{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargamos la data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score,confusion_matrix, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "df=pd.read_csv('breast cancer.csv')\n",
    "df.head()   \n",
    "\n",
    "#preparamos los datos y eliminamos una columna con valores nulos\n",
    "df.drop(['Unnamed: 32', 'id'], axis=1, inplace=True)\n",
    "\n",
    "#imprimimos las nuevas columnas\n",
    "variables=df.columns\n",
    "print(variables)\n",
    "\n",
    "\n",
    "#escogemos las variables y aplicamos el modelo de regresion logistica\n",
    "X = df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean']]\n",
    "y = df['diagnosis']\n",
    "\n",
    "# Mapear las etiquetas 'M' (maligno) a 1 y 'B' (benigno) a 0\n",
    "y = y.map({'M': 1, 'B': 0})\n",
    "\n",
    "# Crea una instancia del modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Ajusta el modelo a los datos\n",
    "model.fit(X, y)\n",
    "\n",
    "# Realiza predicciones con el modelo\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Calcula la precisión del modelo\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "# Calcula y muestra la matriz de confusión\n",
    "confusion = confusion_matrix(y, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(confusion)\n",
    "\n",
    "# Genera un informe de clasificación que incluye precisión, recuperación y F1-score\n",
    "report = classification_report(y, y_pred)\n",
    "print('Informe de Clasificación:')\n",
    "print(report)\n",
    "\n",
    "\n",
    "\n",
    "#evaluamos el modelo, calculamos las metricas de evaluacion para el modelo\n",
    "# Obtener las probabilidades de predicción\n",
    "y_prob = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calcular el AUC-ROC\n",
    "roc_auc = roc_auc_score(y, y_prob)\n",
    "print(f'AUC-ROC: {roc_auc}')\n",
    "\n",
    "# Calcular el AUC-PR\n",
    "prc_auc = average_precision_score(y, y_prob)\n",
    "print(f'AUC-PR: {prc_auc}')\n",
    "\n",
    "# Calcular la curva ROC\n",
    "fpr, tpr, thresholds_roc = roc_curve(y, y_prob)\n",
    "\n",
    "# Calcular la curva PRC\n",
    "precision, recall, thresholds_prc = precision_recall_curve(y, y_prob)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Graficar la curva PRC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Curva PRC (AUC = %0.2f)' % prc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precision-Recall')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "# Mostrar las curvas ROC y PRC\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#desbalanceo de clases luego veremos el efecto que provoca en el modelo de regresion logistica\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler,LabelEncoder\n",
    "\n",
    "# Cargamos los datos\n",
    "df=pd.read_csv('creditcard.csv')\n",
    "# Eliminamos Duplicados\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# Eliminamos Nulos, y los datos \"Time\" y \"Amount\" por no estar correctamente codificadas\n",
    "df=df.dropna()\n",
    "df=df.drop(['Time','Amount'] , axis = 1)\n",
    "col=df.columns.to_list()\n",
    "\n",
    "# Es necesario escalar\n",
    "sc=StandardScaler()\n",
    "\n",
    "# Identifiquemos las variables X e y\n",
    "X=df.drop('Class', axis = 1)\n",
    "Y=df['Class']\n",
    "X=sc.fit_transform(X)\n",
    "print(df['Class'].value_counts())\n",
    "\n",
    "\n",
    "#como podemos ver la clase 0 tiene muchos mas que la clase 1, usaremos SMOTE para corregirlo\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = df.drop(columns=[\"Class\"]).values\n",
    "\n",
    "# Variable dependiente\n",
    "y = df[\"Class\"].values\n",
    "\n",
    "# Estandarizar las características\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Modelo de Regresión Logística sin SMOTE\n",
    "logistic_regression_model = LogisticRegression(random_state=42)\n",
    "logistic_regression_model.fit(X, y)\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos sin SMOTE\n",
    "y_pred = logistic_regression_model.predict(X)\n",
    "\n",
    "# Calcular AUC-ROC sin SMOTE\n",
    "roc_auc = roc_auc_score(y, y_pred)\n",
    "\n",
    "# Calcular AUC-PR sin SMOTE\n",
    "average_precision = average_precision_score(y, y_pred)\n",
    "\n",
    "# Ahora, aplicaremos SMOTE y crearemos el modelo nuevamente\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Modelo de Regresión Logística con SMOTE\n",
    "logistic_regression_model_smote = LogisticRegression(random_state=42)\n",
    "logistic_regression_model_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos con SMOTE\n",
    "y_pred_smote = logistic_regression_model_smote.predict(X)\n",
    "\n",
    "# Calcular AUC-ROC con SMOTE\n",
    "roc_auc_smote = roc_auc_score(y, y_pred_smote)\n",
    "\n",
    "# Calcular AUC-PR con SMOTE\n",
    "average_precision_smote = average_precision_score(y, y_pred_smote)\n",
    "\n",
    "# Imprimir AUC-ROC y AUC-PR para ambos modelos\n",
    "print(\"AUC-ROC sin SMOTE:\", roc_auc)\n",
    "print(\"AUC-PR sin SMOTE:\", average_precision)\n",
    "print(\"AUC-ROC con SMOTE:\", roc_auc_smote)\n",
    "print(\"AUC-PR con SMOTE:\", average_precision_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455aeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Un aumento en el AUC-ROC con SMOTE es común, ya que SMOTE mejora la separación entre las clases, pero una disminución en el AUC-PR puede ocurrir debido a la introducción de ejemplos sintéticos que pueden no ser ideales para la clasificación precisa de la clase minoritaria. La elección de qué métrica es más importante depende del contexto de tu problema. Si la precisión en la detección de la clase minoritaria es crucial, entonces debes prestar más atención al AUC-PR y considerar ajustes adicionales en el modelo o en la técnica de muestreo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
